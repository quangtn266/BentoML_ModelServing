{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xv-tCHWy3leH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af83638f-5b2f-48e6-a973-5fbd19002e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sagemaker\n",
        "from sagemaker import get_execution_role\n",
        "\n",
        "## Setup session\n",
        "sagemaker_session = sagemaker.Session()\n",
        "\n",
        "# default s3 bucket\n",
        "bucket = sagemaker_session.default_bucket()\n",
        "prefix = \"sagemaker/DEMO-pytorch-mnist\"\n",
        "\n",
        "#IAM role\n",
        "role = get_execution_role()\n",
        "\n",
        "# region\n",
        "region = sagemaker_session.boto_session.region_name"
      ],
      "metadata": {
        "id": "rwapEabULE-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transform\n",
        "\n",
        "MNIST.mirrors = [\"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/\"]\n",
        "\n",
        "MNIST(\n",
        "    'data', download=True, transform=transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "JGI8LRPuN3iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare input path for training with estimator.fit()\n",
        "inputs = sagemaker_session.upload_data(path='data', bucket=bucket, key_prefix=prefix)\n",
        "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
      ],
      "metadata": {
        "id": "IYwxwrlDQcN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_training_data_loader(batch_size, training_dir, is_distributed, **kwargs):\n",
        "  logger.infor(\"get train data loader\")\n",
        "  dataset = dataset.MNIST(\n",
        "      training_dir,\n",
        "      download=True,\n",
        "      train=True,\n",
        "      transform=transform.Compose(\n",
        "          [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  train_sampler = (\n",
        "      torch.utils.data.distributed.DistributedSampler(dataset) if is_distributed else None\n",
        "  )\n",
        "\n",
        "  return torch.utils.data.DataLoader(\n",
        "      dataset,\n",
        "      batch_size = batch_size,\n",
        "      shuffle = train_sampler is None,\n",
        "      sampler = train_sampler.\n",
        "      **kwargs\n",
        "  )"
      ],
      "metadata": {
        "id": "DjHw9f3hQ2eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.pytorch import Pytorch\n",
        "# Pytorch configuration\n",
        "estimator = Pytorch(entry_point='mnist.py',role=role, py_version='py3', framework_version='1.8.0', instance_count=2, instance_type='ml.c5.2xlarge',\n",
        "                    hyperparameters={\n",
        "                        'epochs':1,\n",
        "                        'backend': 'gloo'\n",
        "                    })\n",
        "\n",
        "# training\n",
        "estimator.fit({'training': inputs})\n",
        "\n",
        "# deploy\n",
        "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
      ],
      "metadata": {
        "id": "xUv4fxPaRrgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a sample data for inference\n",
        "import gzip\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "data_dir = 'data/MNIST/raw'\n",
        "with gzip.open(os.path.join(data_dir, 't10k-images-idx3-ubyte.gz'), 'rb') as f:\n",
        "  images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28).astype(np.float32)\n",
        "\n",
        "\n",
        "# random select some of the test image\n",
        "mask = random.sample(range(len(images)), 16)\n",
        "mask = np.array(mask, dtype=np.int)\n",
        "\n",
        "# input data\n",
        "data = images(mask)"
      ],
      "metadata": {
        "id": "tK7idIndSm-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "# input data\n",
        "response = predictor.predict(np.expand_dims(data, axis=1))\n",
        "print(\"Raw prediction result:\")\n",
        "print(response)\n",
        "\n",
        "labeled_predictions = list(zip(range(10), response[0]))\n",
        "print(\"labeled predictions: \")\n",
        "print(labeled_predictions)\n",
        "\n",
        "labeled_predictions.sort(key=lambda label_and_prob: 1.0 - label_and_prob[1])\n",
        "print(\"Most likely answer: {}\".format(labeled_predictions[0]))"
      ],
      "metadata": {
        "id": "O4Hx-JGjTSCl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}